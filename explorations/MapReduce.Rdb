<?xml version="1.0"?>
<article xmlns:r="http://www.r-project.org"
         xmlns:xi="http://www.w3.org/2003/XInclude"
	 xmlns:c="http://www.C.org">

<articleinfo>

<title>Map and Reduce Operations</title>

<author><firstname>Duncan</firstname><surname>Temple Lang</surname>
  <affiliation><orgname>University of California at Davis</orgname>
               <orgdiv>Department of Statistics</orgdiv>
  </affiliation>
</author>
</articleinfo>

<section>
<title></title>

<para>
Consider the likelihood calculation
<r:code>
prod(dnorm(x, mu, sigma))
</r:code>
where <r:var>x</r:var> is a vector.
In theory, <r/> might end up with 2 copies of <r:var>x</r:var>.
It doesn't, because  <r:func>prod</r:func> is implemented as a <r:func>.Primitive</r:func> and <r:func>dnorm</r:func> as an <r:func>.External</r:func>.
Similarly, 
<r:code>
sum(log(dnorm(x, mu, sigma)))
</r:code>
involves three loops over vectors  with n elements (where n is the length of <r:var>x</r:var>).
An obvious improvement to this computation is loop fusion.
Essentially, 
<r:code>
sum(log(dnorm(x, mu, sigma)))
</r:code>
is equivalent to 
<c:code><![CDATA[
tmp = NEW_NUMERIC(n);
for(i = 0; i < n; i++)
  tmp[i] = dnorm(x[i], mu, sigma);

for(i = 0; i < n; i++)
  tmp[i] = log(tmp[i]);

total = 0l
for(i = 0; i < n; i++)
  total += tmp[i] 
]]></c:code>

It is reasonably clear that this can be implemented as
<c:code>
total = 0
for(i = 0; i < n; i++)
  total + = log(dnorm(x[i], mu, sigma));
</c:code>
We avoid allocating the intermediate vector <c:var>tmp</c:var>
and we only perform the loop once.
</para>

<para>
In our example, if we know that <r:func>dnorm</r:func>
and <r:func>log</r:func> are element-wise functions
i.e. that return a vector  with the same number of elements
as the input, then it is easy for us to fuse these loops together.
Similarly, if we know that <r:func>sum</r:func> is a
<quote>reduce</quote> function, then we can fuse its operations
into the loop.
</para>
<para>
We can identify these functions as being element-wise or reduce functions,
either manually by declaring them via hints or annotations on the functions,
or by inferring these.
Similarly, we can explicitly write our expression with
<r:code>
Reduce(`+`, Map(log, Map(dnorm, x, mu, sigma)))
</r:code>
This would be horribly inefficient when run in regular <r/>.
<r:code>
x = rnorm(1e6)
mr = system.time(Reduce(`+`, Map(log, Map(dnorm, x, mu, sigma))))
r = system.time(sum(log(dnorm(x, 0, 1))))
</r:code>
There is a speedup by using the vectorized <r/> functions of a factor of approximately
129!  So using this explicit idiom is very costly.
However, we can use it to compile the expressions and then fuse the loops.
</para>
<para>
Let's first manually implement the loop fusion.
This is done in <ulink url="maxLik.c"/>.
We then time the two different implementations for different sizes:
<r:code>
dyn.load("maxLik.so")
N = 10^c(3:9)
tms = lapply(N,
        function(n) {
           x = rnorm(1e7)
           fused = system.time(.Call("R_maxLik", x, 0, 1))
           r = system.time(sum(log(dnorm(x, 0, 1))))
           r/fused
        })
tms = do.call(rbind, tms)
plot(log(N), tms[,3], ylim = c(1, max(tms[,3])))
</r:code>
This basically shows a speedup of a little over 3
which is what we expect.
</para>


<para>
So we now want our compiler to recognize this 
<r:func>Reduce</r:func> with nested calls to <r:func>Map</r:func>.
One of the benefits of being able to generate our own machine code
via <r:pkg>Rllvm</r:pkg> is that we can compile this code differently
from a general or generic compiler for R.
We can recognize this ourselves and call a specific function
to generate the byte code.
We can use this to write the machine code rather than  writing the C code manually.
(See fuseLoop.R ##XXX implement)
</para>


<para>
How often do people use this idiom? Look at the CRAN packages. Not very often.
Is this because it is not of common use, or because it is not well known in the 
<r/> community?  We can explore and identify nested loops,
be they explicit in the form of <r:keyword>for</r:keyword>  loops
</para>

<para>
The approach of making routines process and return a scalar rather than being
vectorized allows them to be easily composed with another routine without
the overhead of having two loops from two vectorized routines.
Additionally, we can generate both scalar and vectorized versions quite easily.
</para>

</section>
<section>
<title>Compiling a Map-Reduce Composition</title>

<para>
So let's compile the expression
<r:code>
Reduce(`+`, Map(log, Map(Dnorm, x, mu, sigma)))
</r:code>
We'll try to leverage the facilities for compiling
from the <omg:pkg>RLLVMCompile</omg:pkg> package
but illustrate how we can add our own effects.
Firstly, we see that there are 3 variables in
the expression - <r:var>x</r:var>, <r:var>mu</r:var> and <r:var>sigma</r:var>.
We can either create a routine which accepts these as inputs or alternatively,
we can capture their current values and put those directly in the code.
We may want to allow the caller to specify which of these to do,
or to allow some of them be inputs (e.g. <r:var>x</r:var>)
and others hard-coded, e.g. <r:var>mu</r:var> and <r:var>sigma</r:var>.
Let's start with 
<r:code>
f = function(x, mu, sigma)
{

}
</r:code>
This leaves all the inputs as parameters.
</para>
<para>
We can explicitly generate the code or we can rewrite the expression
to be a loop:
<r:code>
for(val in x)
   total = total + log(Dnorm(val, mu, sigma))
</r:code>
This latter approach then allows us to use the simple compiler in <omg:pkg>RLLVMCompile</omg:pkg> directly.
Let's try this approach.
<r:code>
f = function(x, mu, sigma)
{
   total = 0
   for(val in x)
      total = total + log(Dnorm(val, mu, sigma))
   total
}
</r:code>

</para>

<para>
See fuseLoop.Rdb
</para>

</section>
</article>