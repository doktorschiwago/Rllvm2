<?xml version="1.0"?>
<article xmlns:r="http://www.r-project.org"
         xmlns:xi="http://www.w3.org/2003/XInclude">

<articleinfo>

<title>Computing Distances</title>

<author><firstname>Duncan</firstname><surname>Temple Lang</surname>
  <affiliation><orgname>University of California at Davis</orgname>
               <orgdiv>Department of Statistics</orgdiv>
  </affiliation>
</author>
</articleinfo>

<section>
<title></title>

<para>
Consider computing distances between all pairs of observations.
We can use the <r:func>dist</r:func> function in <r/> for this.
Some things to note about this function are that a) it
expects a single data frame/matrix, b) it computes all pairwise distances
between the observations in the data frame, not just the pairs in which we are interested,
c) there are a fixed set of known metrics,
d) the code is implemented in <c/> and so less accessible, extensible
and requires more up-front effort to develop,
d) since this is C code, it less adaptable to parallel computation strategies
e.g. running on GPUs. 
If OpenMP is available, the code use parallel computations.
However, the strategy is defined when programmed, not during the <R/> session.
</para>
<para>
Point a) is important since if we have two large separate data sets
(e.g. test and training) and don't want to combine them into a single
data frame for reasons of memory consumption, we have a problem.
The <r:pkg>pdist</r:pkg> package addresses this. However, it implements
only the Euclidean metric! It doesn't use threads or any 
approach to parallelize the computations.
This is an example of the discontinuity in our computing environment - 
things work well when there is a native routine, but if we want it to do
something slightly different, we have to use a very different approach.
</para>
<para>
Point b) is also important when one of the two data sets 
has many more observations than the other.
Suppose we have a data set with 8000 observations and another with 3100.
We end up with 8000 x 3100 = 24,800,000 distances.
When we compute this with <r/>'s <r:func>dist</r:func> function,
we end up computing all 61,599,450 distances and then discard
all but the 24 million we want. So we are computing approximately 
two and half times the number of distances that we actually want.
If we can skip these, we may be able to improve the computational speed over 
<r:func>dist</r:func>.
</para>

<para>
There are several issues we may want to change.  Firstly, we may have
two sets of observations in separate data frames. We have to combine
them into a single data frame or matrix to pass to
<r:func>dist</r:func>.  This involves creating a copy of the original
data sets, consuming more memory.  Secondly, we don't necessarily want
to compute all of the distances between all of the pairs of
observations. Often we only want to compute the distances between each
observation in the first data set and each of the observations in the
second.  We don't want to bother with the extra computation of the
distances of the within data set distances.  Another issue is that we
may want to use a different parallel strategy, e.g. multicore.  Also,
the <r:func>dist</r:func> function converts the input observations to a
<r:class>matrix</r:class>. If the data were originally in a
<r:class>data.frame</r:class>, this creates yet another copy of the
data.  We don't want to have to write code that takes a data frame,
but we could.  Related to this is the fact that matrices are stored
column-wise. So observations stored in rows have values that are not
conveniently and contiguously stored in memory. Instead, the elements
in each observation are separated by a stride given by the number of
rows.  This matters for accessing cached memory.  For a large number
of rows, the elements are further apart and so on different memory pages and
less likely to be together in the cache.  Instead, we'd like to be
able adapt the computations to improve the cache coherency, 
or at least easily explore the effect of the cache coherency.
</para>

<para>
The basic computations for computing the distance are  very simple:
compute the distance for each pair of observations by looping
over each set of observations.  The following <r/> code illustrates this:
<r:code>
<xi:include href="distance.R" parse="text"/>
</r:code>
Here we have two loops - over the pairs of observations. There is an
implicit third loop over the elements of the pairs of observations.
</para>


<para>
We have  a problem passing the array of values 
for each observation to our distance function.
In R, we pass g1[i,] and g2[j,].
R takes the time to create two new vectors
and then passes them to our function <r:func>op</r:func>.
Our <r:func>euclidean</r:func> function
<r:function><![CDATA[
function(x, y)
   sum((x - y)^2)
]]></r:function>
takes these and uses R's vectorization to loop 
</para>
<para>
We can write this euclidean distance as
<r:function><![CDATA[
function(x, y)
  Reduce(`+`, Map(`^`, Map(`-`, x, y), 2))
]]></r:function>
We can recognize this as and fuse the loops.
In the future, we will endeavor to recognize this in regular R code,
i.e. the original version.
</para>


<para>
Regardless of how we write the euclidean distance function for two observations,
the critical aspect is how they access the elements of the two observations.
What is key is that because we are compiling the euclidean function
for use in the distance function, we can arrange how the data are made
available and how that function accesses them. This gives us a great deal of freedom.
We can also compile different versions of our distance function and the 
<r:func>op</r:func> functions to work with data frames and so access the data in different
ways again.
</para>
<para>
We'll assume our two sets of observations are in matrices.
We will loop (i) over the rows of the first matrix
and for each of these, loop over the rows of the
other matrix. 
When we compute the distance for the i-th and j-th observations,
we loop over the elements of the matrices starting
 X + i and Y + j. The next pair of values is 
 X + i + nrow(X) and Y + j + nrow(Y).
 There are p iterations in this third loop.
</para>

<para>
The code is 
<r:function><![CDATA[
dist = 
function(X, Y, nx = nrow(X), ny = nrow(Y), p = ncol(X))
{
  ctr = 1L
  ans = numeric(nx * ny)  # want to do this.
  for(i in 1:nx) {
    for(j in 1:ny) {
       posX = i  # this should be in the i loop. But get wrong answer
       posY = j
       total = 0.0
       for(k in 1:p) {
          total = total + (X[posX]  - Y[posY])^2
          posX = posX + nx
          posY = posY + ny
       }
       ans[ctr] = sqrt(total)
       ctr = ctr + 1L
    }
  }
  ans
}
]]></r:function>
We'd like to conclude this with
<r:code>
matrix(ans, nx, ny, byrow = TRUE)
</r:code>
However, we'll leave this to <r/> code that calls this function.
Similarly, such a wrapper function can provide the values for
the <r:arg>nx</r:arg>, <r:arg>ny</r:arg> and <r:arg>p</r:arg>
parameters.
</para>


<para>
We have lost the convenience and succinct nature of <r/>'s syntax and vector operations.
We have explicitly looped over the p elements of each observation.
We have done this so that we don't have to create intermediate vectors, e.g.
<r:expr eval="false">X[i,]</r:expr> which explicitly needs to create a new numeric vector
to make the elements continigous in memory. 
One of the things we'd like to do is analyze the regular <r/>  code with
<r:expr eval="false">X[i,]</r:expr> and <r:expr eval="false">(X[i,] - Y[j,])^2</r:expr>
and recognize that we can rewrite the computations to avoid creating these intermediate representations of the data.
</para>


<para>
It may not be obvious, but the important part of defining the metric
is within the third-nested loop and is in the expression.
The expression <r:expr eval="false">(X[posX] - Y[posY])^2</r:expr>
computes the squared difference for each variable between to observations.
The next operation is the call to <r:func>sqrt</r:func>.
That computes the final value of the distance.
While it may not be very familiar to <r/> users,
we can readily rewrite these expressions and substitute a different 
computation.
</para>

<para>
Let's test our function to determinate we get the correct results:
<r:test>
X = matrix(rnorm(15), 3, 5)
Y = matrix(rnorm(20), 4, 5)
dist(X, Y)
as.matrix(stats::dist(rbind(X, Y)))[1:3, -(1:3)]
</r:test>

A second test with deterministic input is
<r:test>
A = matrix(as.numeric(1:15), 3,5)
B = matrix(as.numeric(20:1), 4,5)
a = matrix(dist(A, B), 3, 4, byrow = TRUE)
b = as.matrix(stats::dist(rbind(A, B)))[1:3, -(1:3)]
</r:test>

</para>
<para>
Now let's consider compiling the <r/> function above:
<r:code id="compile">
library(RLLVMCompile)
mod = Module()
declareFunction(list(VoidType, Int32Type), "printInt", mod)
llvmAddSymbol("printInt")
distc = compileFunction(dist, REALSXPType, list(DoublePtrType, DoublePtrType, Int32Type, Int32Type, Int32Type), module = mod)
</r:code>

<r:test id="run">
A = matrix(as.numeric(1:15), 3,5)
B = matrix(as.numeric(20:1), 4,5)

A = matrix(rnorm(15), 3,5)
B = matrix(rnorm(20), 4,5)

ee = ExecutionEngine(distc)
ans = .llvm(distc, A, B, nrow(A), nrow(B), ncol(A), .ee = ee)
ans = matrix(ans, nrow(A), nrow(B), byrow = TRUE)
true = as.matrix(stats::dist(rbind(A, B)))[ 1:nrow(A), - (1:nrow(A))]
all(ans == true) 
</r:test>

<r:test id="test">
p = 40L
n1 = 8000L
n2 = 1000L
A = matrix(rnorm(n1 * p), n1, p)
B = matrix(rnorm(n2 * p), n2, p)

lf = function(A, B, .ee = ExecutionEngine(distc)) {
   matrix(.llvm(distc, A, B, nrow(A), nrow(B), ncol(A), .ee = .ee), nrow(A), nrow(B), byrow = TRUE)
}

rm(dist)
rf = function(A, B) {
    as.matrix(dist(rbind(A, B)))[ 1:nrow(A), - (1:nrow(A)) ]
}
</r:test>
<r:test id="doTiming"><![CDATA[  
tm.ll = system.time(a <- lf(A, B, ee))
tm.r = system.time(b <- rf(A, B))
all.equal(a, b)  # mismatch on dimnames should be only issue.

res = structure(list(llvm = tm.ll, r.dist = tm.r), 
                 session = sessionInfo(), when = Sys.time(), system = Sys.info())
id = sprintf("distance.tm.%d:%d:%d_%s", n1, n2, p, Sys.info()["sysname"])
assign(id, res, globalenv())
save(list = id, file = sprintf("%s.rda", id))
]]>
<r:output><![CDATA[ 
 # p = 40, n1 = 8000, n2 = 3100, 
rbind(tm.ll, tm.r)[,1:3] 
# OS X   llvm 3.2
      user.self sys.self elapsed
tm.ll    25.521    0.142  25.664
tm.r     18.850    2.821  21.673

# Linux (jasper) llvm 3.3
      user.self sys.self elapsed
tm.ll    40.946    0.234  41.196
tm.r    128.001    5.412 133.437
]]></r:output>
</r:test>
The results show the LLVM code is  about 18% slower on OS X.
On the Linux box, the results are a lot slower for some reason.
However, we are comparing like-with-like, and the LLVM code is
about 3 times faster.
</para>
<para>

<r:test>
if(require("pdist")) {
pf = function(A, B)
       as.matrix(pdist(A, B))

system.time(pf(A, B))
}
<r:output><![CDATA[
# p = 40, 8000 3100
# OS X
   user  system elapsed 
  2.957   0.561   3.519 
# Linux
  user  system elapsed
 12.313   1.064  13.379
]]></r:output>
</r:test>
Note that we convert the result back to a matrix
which we don't necessarily have to do to use the results.
This is the same as <r:func>dist</r:func>.
However, it often makes sense to do this 
both because we want the matrix and also because
it makes subsequent computations faster (avoiding methods
for subsetting and allocating temporary vectors for rows or columns).
</para>
<para>
Note that the <r/> code causes the system time to be significant.
This is probably points to memory allocation.
</para>
<para>

Here we assume that we are going to return an <r/> numeric vector
with the distance values. We pass in the two matrices, the
number of rows of each and the number of columns that is the same for each matrix.
The final input is the numeric vector into which we will insert the results.
It will be up to the <r/> code that calls this to reorganize the result into a matrix.
</para>
<para>
As we have indicated, we can change this code to access the actual values
in the individual observations in a different way.
We could accept two data frames. We would then compute 
<r:expr eval="false">X[posX]</r:expr> and <r:expr eval="false">Y[posY]</r:expr>
very differently. Indeed, we may want to leave the code as
<r:expr eval="false">X[i,k]</r:expr> and <r:expr eval="false">Y[j,k]</r:expr>
and leave the compiler to understand what this actually means and map it to a
computation, e.g <r:expr eval="false">X[ i + nx * j]</r:expr> or
<r:expr eval="false">REAL(VECTOR_ELT(X, j))[i]</r:expr>.
This is something that can be determined at compile time. 
We can generate code for different inputs. 
The latter access assumes the variable is numeric. 
We can add extra code to handle different types for the columns
in an effort to avoid copying any data to a different type.
Indeed, if the data are sufficiently large, it may be
prudent to compile this <r/> code specifically  for
a particular data set, knowing the types of its columns.
</para>
</section>

<r:code eval="false" id="source">
xmlSourceFunctions("distance.Rdb", verbose = FALSE); xmlSource("distance.Rdb", ids = "compile"); xmlSource("distance.Rdb", xnodes = "//r:test[@id = 'run' or @id = 'test']")
</r:code>
</article>